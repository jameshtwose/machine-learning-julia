<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>neuropy.machine_learning_classification &#8212; neuropy v1.5.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="../../_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="../../_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../../_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html">
           </a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">

                <li><a href="../../index.html">Home</a></li>


              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html"><code class="docutils literal notranslate"><span class="pre">neuropy.anomaly_detection</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.cluster_analysis"><code class="docutils literal notranslate"><span class="pre">neuropy.cluster_analysis</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.config"><code class="docutils literal notranslate"><span class="pre">neuropy.config</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.correlation"><code class="docutils literal notranslate"><span class="pre">neuropy.correlation</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.dimensionality_reduction"><code class="docutils literal notranslate"><span class="pre">neuropy.dimensionality_reduction</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.frequency_domain"><code class="docutils literal notranslate"><span class="pre">neuropy.frequency_domain</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.frequentist_statistics"><code class="docutils literal notranslate"><span class="pre">neuropy.frequentist_statistics</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.group_analysis"><code class="docutils literal notranslate"><span class="pre">neuropy.group_analysis</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.internal_composite"><code class="docutils literal notranslate"><span class="pre">neuropy.internal_composite</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.internal_utils"><code class="docutils literal notranslate"><span class="pre">neuropy.internal_utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.machine_learning_classification"><code class="docutils literal notranslate"><span class="pre">neuropy.machine_learning_classification</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.machine_learning_regression"><code class="docutils literal notranslate"><span class="pre">neuropy.machine_learning_regression</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.machine_learning_utils"><code class="docutils literal notranslate"><span class="pre">neuropy.machine_learning_utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.utils"><code class="docutils literal notranslate"><span class="pre">neuropy.utils</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html#module-neuropy.vumc_utils"><code class="docutils literal notranslate"><span class="pre">neuropy.vumc_utils</span></code></a></li>
</ul>
</ul>
</li>

                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"></ul>
</li>






          </ul>



<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>

        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">

  <h1>Source code for neuropy.machine_learning_classification</h1><div class="highlight"><pre>
<span></span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Submodule machine_learning_classification.py includes the following functions: &lt;br&gt;</span>
<span class="sd">  - **plot_decision_boundary():**  Generate a simple plot of the decision boundary of a classifier. &lt;br&gt;</span>
<span class="sd">  - **_bootstrap_auc():** Internal function to bootstrap auc &lt;br&gt;</span>
<span class="sd">  - **summary_performance_metrics_classification():** Summary evaluation metrics specific to a binary classification. &lt;br&gt;</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">ListedColormap</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">auc</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">balanced_accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>


<div class="viewcode-block" id="plot_decision_boundary"><a class="viewcode-back" href="../../usage.html#neuropy.machine_learning_classification.plot_decision_boundary">[docs]</a><span class="k">def</span> <span class="nf">plot_decision_boundary</span><span class="p">(</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
    <span class="n">clf</span><span class="p">,</span>
    <span class="n">title</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">legend_title</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">h</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">11.7</span><span class="p">,</span> <span class="mf">8.27</span><span class="p">),</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate a simple plot of the decision boundary of a classifier.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape (n_samples, n_features)</span>
<span class="sd">        Classifier vector, where n_samples is the number of samples and</span>
<span class="sd">        n_features is the number of features.</span>
<span class="sd">    y : array-like, shape (n_samples)</span>
<span class="sd">        Target relative to X for classification. Datatype should be integers.</span>
<span class="sd">    clf : scikit-learn algorithm</span>
<span class="sd">        An object that has the `predict` and `predict_proba` methods</span>
<span class="sd">    h : int (default: 0.05)</span>
<span class="sd">        Step size in the mesh</span>
<span class="sd">    title : string</span>
<span class="sd">        Title for the plot.</span>
<span class="sd">    legend_title : string</span>
<span class="sd">        Legend title for the plot.</span>
<span class="sd">    figsize: tuple (default: (11.7, 8.27))</span>
<span class="sd">        Width and height of the figure in inches</span>

<span class="sd">    Returns</span>
<span class="sd">    ----------</span>
<span class="sd">    boundaries: Figure</span>
<span class="sd">        Properties of the figure can be changed later, e.g. use `boundaries.axes[0].set_ylim(0,100)` to change ylim</span>

<span class="sd">    Examples</span>
<span class="sd">    ----------</span>
<span class="sd">    &gt;&gt;&gt; import seaborn as sns</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.svm import SVC</span>
<span class="sd">    &gt;&gt;&gt; data = sns.load_dataset(&quot;iris&quot;)</span>
<span class="sd">    &gt;&gt;&gt; # convert the target from string to category to numeric as sklearn cannot handle strings as target</span>
<span class="sd">    &gt;&gt;&gt; y = data[&quot;species&quot;]</span>
<span class="sd">    &gt;&gt;&gt; X = data[[&quot;sepal_length&quot;, &quot;sepal_width&quot;]]</span>
<span class="sd">    &gt;&gt;&gt; clf = SVC(kernel=&quot;rbf&quot;, gamma=2, C=1, probability=True)</span>
<span class="sd">    &gt;&gt;&gt; _ = plot_decision_boundary(X=X, y=y, clf=clf, title = &#39;Decision Boundary&#39;, legend_title = &quot;Species&quot;)</span>
<span class="sd">    &gt;&gt;&gt; # plt.show()</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X must contains only two features.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
        <span class="n">pd</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_integer_dtype</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">pd</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_object_dtype</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">pd</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_categorical_dtype</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="s2">&quot;The target variable y can only have the following dtype: [int, object, category].&quot;</span>
        <span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;category&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">codes</span><span class="o">.</span><span class="n">values</span>

    <span class="c1"># Create color map (first 5 colors are from Neurokeys, later ones are added for contrast)</span>
    <span class="n">full_col_list</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;#2167C5&quot;</span><span class="p">,</span>
        <span class="s2">&quot;#EB5E23&quot;</span><span class="p">,</span>
        <span class="s2">&quot;#4A4A4A&quot;</span><span class="p">,</span>
        <span class="s2">&quot;#F5A75D&quot;</span><span class="p">,</span>
        <span class="s2">&quot;#9B9B9B&quot;</span><span class="p">,</span>
        <span class="s2">&quot;#3D9140&quot;</span><span class="p">,</span>
        <span class="s2">&quot;#FFE119&quot;</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_col_list</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;More labels in the data then colors in the color list. Either reduce the number of labels or expend the color list&quot;</span>
        <span class="p">)</span>
    <span class="n">sub_col_list</span> <span class="o">=</span> <span class="n">full_col_list</span><span class="p">[</span><span class="mi">0</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">))]</span>
    <span class="n">cmap_bold</span> <span class="o">=</span> <span class="n">ListedColormap</span><span class="p">(</span><span class="n">sub_col_list</span><span class="p">)</span>

    <span class="c1"># Try to include a mapping in a later release (+ show categorical labels in the legend)</span>

    <span class="n">_</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># Plot the decision boundary. For that, we will assign a color to each</span>
    <span class="c1"># point in the mesh [x_min, x_max]x[y_min, y_max].</span>
    <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">Z_proba</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">Z_max</span> <span class="o">=</span> <span class="n">Z_proba</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Take the class with highest probability</span>
    <span class="n">Z_max</span> <span class="o">=</span> <span class="n">Z_max</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># Put the result into a color plot</span>
    <span class="n">boundaries</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_bold</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="p">(</span><span class="n">Z_max</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">h</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_bold</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span>
    <span class="p">)</span>

    <span class="c1"># Plot also the training points</span>
    <span class="n">training</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap_bold</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">xx</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">yy</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">right</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

    <span class="c1"># Add legend colors</span>
    <span class="n">leg1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
        <span class="o">*</span><span class="n">training</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">(),</span>
        <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">borderaxespad</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
        <span class="n">handlelength</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">handletextpad</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="n">legend_title</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Add legend sizes</span>
    <span class="n">l1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.4</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">h</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
    <span class="n">l2</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.6</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">h</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
    <span class="n">l3</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.8</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">h</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>
    <span class="n">l4</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">h</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">)</span>

    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;0.4&quot;</span><span class="p">,</span> <span class="s2">&quot;0.6&quot;</span><span class="p">,</span> <span class="s2">&quot;0.8&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">]</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
        <span class="p">[</span><span class="n">l1</span><span class="p">,</span> <span class="n">l2</span><span class="p">,</span> <span class="n">l3</span><span class="p">,</span> <span class="n">l4</span><span class="p">],</span>
        <span class="n">labels</span><span class="p">,</span>
        <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">borderaxespad</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">handlelength</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">handletextpad</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Probabilities&quot;</span><span class="p">,</span>
        <span class="n">scatterpoints</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">boundaries</span></div>


<span class="k">def</span> <span class="nf">_bootstrap_auc</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">use_probabilities</span><span class="p">,</span> <span class="n">bootstraps</span><span class="p">,</span> <span class="n">fold_size</span><span class="p">,</span> <span class="n">random_state</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Internal function to bootstrap auc.</span>

<span class="sd">    Originates from the AI in healthcare specialization of coursera. https://www.coursera.org/specializations/ai-healthcare</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model:</span>
<span class="sd">        The fitted sklearn model.</span>
<span class="sd">    X_test: pd.Series</span>
<span class="sd">        The predictors used to match to y_true.</span>
<span class="sd">    y_true: pd.Series</span>
<span class="sd">        The actual binary targets.</span>
<span class="sd">    classes: list(str)</span>
<span class="sd">        List with the name of the classes in string format.</span>
<span class="sd">    bootstraps: int</span>
<span class="sd">        The number of bootstraps.</span>
<span class="sd">    fold_size: int</span>
<span class="sd">        The number of folds.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">use_probabilities</span><span class="p">:</span>
        <span class="n">y_pred_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span> <span class="s2">&quot;pred&quot;</span><span class="p">:</span> <span class="n">y_pred_proba</span><span class="p">})</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span> <span class="s2">&quot;pred&quot;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">})</span>

    <span class="n">statistics</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">bootstraps</span><span class="p">)</span>

    <span class="n">df_pos</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">df_neg</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">prevalence</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_pos</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

    <span class="c1"># get positive examples for stratified sampling</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bootstraps</span><span class="p">):</span>
        <span class="c1"># stratified sampling of positive and negative examples</span>
        <span class="n">pos_sample</span> <span class="o">=</span> <span class="n">df_pos</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="n">n</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">fold_size</span> <span class="o">*</span> <span class="n">prevalence</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span>
        <span class="p">)</span>
        <span class="n">neg_sample</span> <span class="o">=</span> <span class="n">df_neg</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="n">n</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">fold_size</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">prevalence</span><span class="p">)),</span>
            <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">y_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">pos_sample</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">neg_sample</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">])</span>
        <span class="n">pred_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">pos_sample</span><span class="o">.</span><span class="n">pred</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">neg_sample</span><span class="o">.</span><span class="n">pred</span><span class="o">.</span><span class="n">values</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">use_probabilities</span><span class="p">:</span>
            <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_sample</span><span class="p">,</span> <span class="n">pred_sample</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_sample</span><span class="p">,</span> <span class="n">pred_sample</span><span class="p">)</span>

        <span class="n">statistics</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">score</span>

    <span class="n">mean</span> <span class="o">=</span> <span class="n">statistics</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">max_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">statistics</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">)</span>
    <span class="n">min_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">statistics</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mean</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (95% CI </span><span class="si">{</span><span class="n">min_</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">max_</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">]</span>


<div class="viewcode-block" id="summary_performance_metrics_classification"><a class="viewcode-back" href="../../usage.html#neuropy.machine_learning_classification.summary_performance_metrics_classification">[docs]</a><span class="k">def</span> <span class="nf">summary_performance_metrics_classification</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">bootstraps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">fold_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">69420</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Summary of different evaluation metrics specific to a single class classification learning problem.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The function returns the following metrics:</span>
<span class="sd">    - true positive (TP): The model classifies the example as positive, and the actual label also positive.</span>
<span class="sd">    - false positive (FP): The model classifies the example as positive, but the actual label is negative.</span>
<span class="sd">    - true negative (TN): The model classifies the example as negative, and the actual label is also negative.</span>
<span class="sd">    - false negative (FN): The model classifies the example as negative, but the label is actually positive.</span>
<span class="sd">    - accuracy: The fractions of predictions the model got right.</span>
<span class="sd">    - prevalance: The proportion of positive examples. Where y=1.</span>
<span class="sd">    - sensitivity: The probability that our test outputs positive given that the case is actually positive.</span>
<span class="sd">    - specificity: The probability that the test outputs negative given that the case is actually negative.</span>
<span class="sd">    - positive predictive value: The proportion of positive predictions that are true positives.</span>
<span class="sd">    - negative predictive value: The proportion of negative predictions that are true negatives.</span>
<span class="sd">    - auc: A measure of goodness of fit.</span>
<span class="sd">    - bootstrapped auc: The bootstrap estimates the uncertainty by resampling the dataset with replacement.</span>
<span class="sd">    - F1: The harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn import datasets</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import train_test_split</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; data = datasets.load_breast_cancer()</span>
<span class="sd">    &gt;&gt;&gt; df = pd.DataFrame(data.data, columns=data.feature_names)</span>
<span class="sd">    &gt;&gt;&gt; df[&#39;target&#39;] = data.target</span>
<span class="sd">    &gt;&gt;&gt; X = data.data</span>
<span class="sd">    &gt;&gt;&gt; y = data.target</span>
<span class="sd">    &gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(X, y)</span>
<span class="sd">    &gt;&gt;&gt; clf = KNeighborsClassifier(n_neighbors=6)</span>
<span class="sd">    &gt;&gt;&gt; clf.fit(X_train, y_train)</span>
<span class="sd">    &gt;&gt;&gt; y_pred = clf.predict(X_test)</span>
<span class="sd">    &gt;&gt;&gt; summary_performance_metrics_classification(y_true=y_test, y_pred=y_pred)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model: sklearn.model</span>
<span class="sd">        A fitted sklearn model with predict() and predict_proba() methods.</span>
<span class="sd">    X_test: pd.DataFrame</span>
<span class="sd">        A data frame used to run predict the target values (y_pred).</span>
<span class="sd">    y_true: pd.Series or np.arrays</span>
<span class="sd">        Binary true values.</span>
<span class="sd">    bootstraps: int</span>
<span class="sd">    fold_size: int</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    pd.DataFrame</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1">## Layout of the logic for using &quot;predict_proba&quot; or not in the AUC calculations</span>

    <span class="c1"># # check if the fitted model has the &quot;predict_proba&quot; attribute</span>
    <span class="c1"># if &quot;predict_proba&quot; in dir(model):</span>
    <span class="c1">#     # check that the fitted model has the &quot;probability&quot; attribute</span>
    <span class="c1">#     if &quot;probability&quot; in dir(model):</span>
    <span class="c1">#         # and that it is set to True (this can be the case for SVC)</span>
    <span class="c1">#         if model.probability:</span>
    <span class="c1">#             predict_proba_bool = True</span>
    <span class="c1">#         else:</span>
    <span class="c1">#             predict_proba_bool = False</span>
    <span class="c1">#     else:</span>
    <span class="c1">#         # the model has &quot;predict_proba and no &quot;probability&quot; boolean so it 100% has &quot;predict_proba&quot;</span>
    <span class="c1">#         predict_proba_bool = True</span>
    <span class="c1"># else:</span>
    <span class="c1">#     # the model has no &quot;predict_proba&quot; attribute so probabilities are not used</span>
    <span class="c1">#     predict_proba_bool = False</span>

    <span class="c1"># check if the fitted model has the &quot;predict_proba&quot; attribute</span>
    <span class="k">if</span> <span class="s2">&quot;predict_proba&quot;</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
        <span class="c1"># check that the fitted model has the &quot;probability&quot; attribute</span>
        <span class="k">if</span> <span class="s2">&quot;probability&quot;</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
            <span class="c1"># and that it is set to True (this can be the case for SVC)</span>
            <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">probability</span><span class="p">:</span>
                <span class="n">predict_proba_bool</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">y_pred_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                <span class="c1"># auc</span>
                <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">auc_score</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">predict_proba_bool</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The classifier </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="si">}</span><span class="s2"> does have the &#39;predict_proba&#39; method, however it does not have&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; the &#39;probability&#39; parameter set to True, hence model evaluation metrics will be based on &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;binary predictions&quot;</span>
                <span class="p">)</span>
                <span class="n">auc_score</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># the model has &quot;predict_proba and no &quot;probability&quot; boolean so it 100% has &quot;predict_proba&quot;</span>
            <span class="n">predict_proba_bool</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">y_pred_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="c1"># auc</span>
            <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">auc_score</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># the model has no &quot;predict_proba&quot; attribute so probabilities are not used</span>
        <span class="n">predict_proba_bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The classifier </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="si">}</span><span class="s2"> does not have the &#39;predict_proba&#39; method, hence &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;model evaluation metrics will be based on binary predictions&quot;</span>
        <span class="p">)</span>
        <span class="n">auc_score</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="c1"># bootstrapped auc</span>
    <span class="n">bootstrap_auc_metric</span> <span class="o">=</span> <span class="n">_bootstrap_auc</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">X_test</span><span class="p">,</span>
        <span class="n">y_true</span><span class="p">,</span>
        <span class="n">use_probabilities</span><span class="o">=</span><span class="n">predict_proba_bool</span><span class="p">,</span>
        <span class="n">bootstraps</span><span class="o">=</span><span class="n">bootstraps</span><span class="p">,</span>
        <span class="n">fold_size</span><span class="o">=</span><span class="n">fold_size</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># TP, TN, FP, FN</span>
    <span class="n">confusion_matrix_metric</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">TN</span> <span class="o">=</span> <span class="n">confusion_matrix_metric</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">FP</span> <span class="o">=</span> <span class="n">confusion_matrix_metric</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">FN</span> <span class="o">=</span> <span class="n">confusion_matrix_metric</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">TP</span> <span class="o">=</span> <span class="n">confusion_matrix_metric</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># accuracy</span>
    <span class="n">accuracy_score_metric</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="c1"># balanced accuracy</span>
    <span class="n">balanced_accuracy_score_metric</span> <span class="o">=</span> <span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="c1"># prevalance</span>
    <span class="n">prevalence</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># sensitivity</span>
    <span class="n">sensitivity</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>

    <span class="c1"># specificity</span>
    <span class="n">specificity</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>

    <span class="c1"># positive predictive value</span>
    <span class="n">PPV</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>

    <span class="c1"># negative predictive value</span>
    <span class="n">NPV</span> <span class="o">=</span> <span class="n">TN</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>

    <span class="c1"># F1</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="n">df_metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;TN&quot;</span><span class="p">:</span> <span class="n">TN</span><span class="p">,</span>
            <span class="s2">&quot;FP&quot;</span><span class="p">:</span> <span class="n">FP</span><span class="p">,</span>
            <span class="s2">&quot;FN&quot;</span><span class="p">:</span> <span class="n">FN</span><span class="p">,</span>
            <span class="s2">&quot;TP&quot;</span><span class="p">:</span> <span class="n">TP</span><span class="p">,</span>
            <span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">accuracy_score_metric</span><span class="p">,</span>
            <span class="s2">&quot;Balanced Accuracy&quot;</span><span class="p">:</span> <span class="n">balanced_accuracy_score_metric</span><span class="p">,</span>
            <span class="s2">&quot;Prevalence&quot;</span><span class="p">:</span> <span class="n">prevalence</span><span class="p">,</span>
            <span class="s2">&quot;Sensitivity&quot;</span><span class="p">:</span> <span class="n">sensitivity</span><span class="p">,</span>
            <span class="s2">&quot;Specificity&quot;</span><span class="p">:</span> <span class="n">specificity</span><span class="p">,</span>
            <span class="s2">&quot;PPV&quot;</span><span class="p">:</span> <span class="n">PPV</span><span class="p">,</span>
            <span class="s2">&quot;NPV&quot;</span><span class="p">:</span> <span class="n">NPV</span><span class="p">,</span>
            <span class="s2">&quot;auc&quot;</span><span class="p">:</span> <span class="n">auc_score</span><span class="p">,</span>
            <span class="s2">&quot;Mean AUC (CI 5</span><span class="si">%-95%</span><span class="s2">)&quot;</span><span class="p">:</span> <span class="n">bootstrap_auc_metric</span><span class="p">,</span>
            <span class="s2">&quot;F1&quot;</span><span class="p">:</span> <span class="n">f1</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;scores&quot;</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">df_metrics</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span></div>
</pre></div>

    </div>

  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>

        <br/>


    </p>
    <p>
        &copy; Copyright 2022, Neurocast Data Science Team.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>
